{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# download_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "# Make sure your .env file is in the same directory as your notebook or Python script,\n",
    "# or provide the full path to load_dotenv()\n",
    "load_dotenv()\n",
    "\n",
    "def get_db_config():\n",
    "    \"\"\"Get database configuration from environment variables.\"\"\"\n",
    "    return {\n",
    "        'host': os.getenv('DB_HOST', 'localhost'),\n",
    "        'user': os.getenv('DB_USERNAME'),\n",
    "        'password': os.getenv('DB_PASS'),\n",
    "        'database': os.getenv('DB_NAME'),\n",
    "        'port': int(os.getenv('DB_PORT', '3306')),\n",
    "        'charset': os.getenv('DB_CHARSET', 'utf8mb4'),\n",
    "        'collation': os.getenv('DB_COLLATION', 'utf8mb4_general_ci')\n",
    "    }\n",
    "\n",
    "def create_connection():\n",
    "    \"\"\"Create a database connection from .env configuration.\"\"\"\n",
    "    connection = None\n",
    "    db_config = get_db_config()\n",
    "    try:\n",
    "        connection = mysql.connector.connect(**db_config)\n",
    "        if connection.is_connected():\n",
    "            print(f\"Successfully connected to MariaDB: {db_config['user']}@{db_config['host']}/{db_config['database']}\")\n",
    "            return connection\n",
    "    except Error as e:\n",
    "        print(f\"Error connecting to MariaDB: {e}\")\n",
    "        print(\"\\nConnection details (excluding password):\")\n",
    "        safe_config = {k: v for k, v in db_config.items() if k != 'password'}\n",
    "        print(safe_config)\n",
    "        return None\n",
    "\n",
    "def list_tables():\n",
    "    \"\"\"List all available tables in the database. Creates and closes its own connection.\"\"\"\n",
    "    connection = create_connection()\n",
    "    if not connection:\n",
    "        # print(\"Failed to connect to database for listing tables.\") # create_connection already prints\n",
    "        return None\n",
    "    \n",
    "    cursor = None\n",
    "    table_names_list = None\n",
    "    try:\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"SHOW TABLES\")\n",
    "        tables_data = cursor.fetchall()\n",
    "        \n",
    "        if not tables_data:\n",
    "            print(\"No tables found in the database.\")\n",
    "            table_names_list = []\n",
    "        else:\n",
    "            print(\"\\nAvailable tables:\")\n",
    "            table_names_list = [table[0] for table in tables_data]\n",
    "            for i, table_name_item in enumerate(table_names_list, 1):\n",
    "                print(f\"{i}. {table_name_item}\")\n",
    "        \n",
    "        return table_names_list\n",
    "    \n",
    "    except Error as e:\n",
    "        print(f\"Error listing tables: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        if connection and connection.is_connected():\n",
    "            if cursor:\n",
    "                cursor.close()\n",
    "            connection.close()\n",
    "\n",
    "def _list_all_tables_internal(connection):\n",
    "    \"\"\"\n",
    "    List all available tables using an existing connection. Internal use.\n",
    "    Returns a list of table names, or None on error.\n",
    "    \"\"\"\n",
    "    cursor = None\n",
    "    try:\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"SHOW TABLES\")\n",
    "        tables_data = cursor.fetchall()\n",
    "        if not tables_data:\n",
    "            return []\n",
    "        return [table[0] for table in tables_data]\n",
    "    except Error as e:\n",
    "        print(f\"Error listing tables internally: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        if cursor:\n",
    "            cursor.close()\n",
    "\n",
    "def _download_single_table_to_df_internal(connection, table_name):\n",
    "    \"\"\"\n",
    "    Fetches all data from a single table and returns it as a Pandas DataFrame.\n",
    "    Uses an existing connection. Internal use.\n",
    "    Returns DataFrame on success (can be empty if table has no rows).\n",
    "    Returns None if table doesn't exist or a database error occurs.\n",
    "    \"\"\"\n",
    "    cursor = None\n",
    "    try:\n",
    "        cursor = connection.cursor(dictionary=True)\n",
    "        cursor.execute(f\"SHOW TABLES LIKE %s\", (table_name,))\n",
    "        if not cursor.fetchone():\n",
    "            print(f\"Table '{table_name}' does not exist in the database.\")\n",
    "            return None\n",
    "        \n",
    "        query = f\"SELECT * FROM `{table_name}`\"\n",
    "        cursor.execute(query)\n",
    "        rows = cursor.fetchall()\n",
    "        \n",
    "        if not rows:\n",
    "            print(f\"Table '{table_name}' is empty.\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        df = pd.DataFrame(rows)\n",
    "        print(f\"Fetched {len(df)} rows from '{table_name}'.\")\n",
    "        return df\n",
    "        \n",
    "    except Error as e:\n",
    "        print(f\"Error fetching data for table '{table_name}': {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        if cursor:\n",
    "            cursor.close()\n",
    "\n",
    "def download_data(tables_to_download, output_dir=\".\", output_format='csv'):\n",
    "    \"\"\"\n",
    "    Download specified table(s) from MariaDB.\n",
    "\n",
    "    Args:\n",
    "        tables_to_download:\n",
    "            - str: Name of a single table.\n",
    "            - list: A list of table names.\n",
    "            - 'all': String literal to download all tables.\n",
    "        output_dir (str): Directory to save CSV files. Defaults to current directory.\n",
    "                          Ignored if output_format is 'pandas'. Created if it doesn't exist for CSV.\n",
    "        output_format (str): 'csv' or 'pandas'.\n",
    "\n",
    "    Returns:\n",
    "        - If output_format is 'csv':\n",
    "            - True if all requested operations were successful, False otherwise.\n",
    "        - If output_format is 'pandas':\n",
    "            - For a single table request: DataFrame if successful, None otherwise.\n",
    "            - For multiple tables or 'all': Dict[str, DataFrame]. Empty dict if no tables\n",
    "              were processed/found or all failed. Individual table entries might be missing if\n",
    "              that specific table failed.\n",
    "        - Special case for pandas: If initial connection fails, returns None for single table request,\n",
    "          or an empty dict for multiple/'all' requests.\n",
    "    \"\"\"\n",
    "    connection = create_connection()\n",
    "    if not connection:\n",
    "        # print(\"Failed to connect to database for downloading data.\") # create_connection prints\n",
    "        if output_format == 'pandas':\n",
    "            is_single_req = isinstance(tables_to_download, str) and tables_to_download.lower() != 'all'\n",
    "            return None if is_single_req else {}\n",
    "        return False\n",
    "\n",
    "    results_dfs = {} if output_format == 'pandas' else None\n",
    "    overall_success = True \n",
    "    \n",
    "    table_names_to_process = []\n",
    "    is_single_table_request = False\n",
    "\n",
    "    try:\n",
    "        if isinstance(tables_to_download, str) and tables_to_download.lower() == 'all':\n",
    "            # print(\"Action: Attempting to download all tables.\")\n",
    "            fetched_tables = _list_all_tables_internal(connection)\n",
    "            if fetched_tables is None: \n",
    "                print(\"Error: Failed to retrieve list of all tables from the database.\")\n",
    "                overall_success = False\n",
    "            elif not fetched_tables:\n",
    "                print(\"Info: No tables found in the database to download.\")\n",
    "            else:\n",
    "                table_names_to_process = fetched_tables\n",
    "        elif isinstance(tables_to_download, list):\n",
    "            if not tables_to_download:\n",
    "                print(\"Info: No tables specified in the list to download.\")\n",
    "            # else:\n",
    "                # print(f\"Action: Attempting to download tables: {', '.join(tables_to_download)}\")\n",
    "            table_names_to_process = tables_to_download\n",
    "        elif isinstance(tables_to_download, str):\n",
    "            # print(f\"Action: Attempting to download table: '{tables_to_download}'\")\n",
    "            table_names_to_process = [tables_to_download]\n",
    "            is_single_table_request = True\n",
    "        else:\n",
    "            print(\"Error: Invalid 'tables_to_download' argument. Must be a table name (str), list of names, or 'all'.\")\n",
    "            overall_success = False\n",
    "\n",
    "        if not overall_success:\n",
    "            if output_format == 'pandas':\n",
    "                return None if is_single_table_request else {}\n",
    "            return False\n",
    "\n",
    "        if not table_names_to_process and overall_success: \n",
    "            if output_format == 'pandas':\n",
    "                 return None if is_single_table_request else {}\n",
    "            return True \n",
    "\n",
    "        if output_format == 'csv' and table_names_to_process: # Create dir only if CSV and tables exist\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        for table_name in table_names_to_process:\n",
    "            print(f\"\\nProcessing table: '{table_name}'...\")\n",
    "            df = _download_single_table_to_df_internal(connection, table_name)\n",
    "\n",
    "            if df is not None: \n",
    "                if output_format == 'csv':\n",
    "                    if not df.empty:\n",
    "                        filename = os.path.join(output_dir, f\"{table_name}.csv\")\n",
    "                        try:\n",
    "                            df.to_csv(filename, index=False)\n",
    "                            print(f\"Data from '{table_name}' saved to {filename}\")\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error saving table '{table_name}' to CSV: {e}\")\n",
    "                            overall_success = False\n",
    "                elif output_format == 'pandas':\n",
    "                    results_dfs[table_name] = df\n",
    "            else: \n",
    "                overall_success = False \n",
    "                if is_single_table_request and output_format == 'csv':\n",
    "                    break \n",
    "\n",
    "    except Error as e: \n",
    "        print(f\"A database error occurred during the download process: {e}\")\n",
    "        overall_success = False\n",
    "    except Exception as e: \n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        overall_success = False\n",
    "    finally:\n",
    "        if connection and connection.is_connected():\n",
    "            connection.close()\n",
    "            print(\"\\nDatabase connection (for downloading data) closed.\")\n",
    "\n",
    "    if output_format == 'pandas':\n",
    "        if is_single_table_request:\n",
    "            if table_names_to_process: \n",
    "                return results_dfs.get(table_names_to_process[0])\n",
    "            return None \n",
    "        return results_dfs \n",
    "    else: \n",
    "        return overall_success\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================================================================\n",
    "# Example Usage for IPython Notebook (copy and paste cells)\n",
    "# ==============================================================================\n",
    "#\n",
    "# **Instructions for Notebook:**\n",
    "# 1. Place this entire script (including the functions above) into a single\n",
    "#    notebook cell and run it. This defines all the necessary functions.\n",
    "# 2. In subsequent cells, you can use the example blocks below.\n",
    "# 3. Ensure your .env file is in the same directory as your notebook or\n",
    "#    provide the full path to `load_dotenv()` at the top.\n",
    "# 4. Modify `TABLE_NAME_SINGLE`, `TABLE_NAMES_MULTIPLE`, and `CSV_DIR` as needed.\n",
    "#\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# --- Configuration (set these once in a cell if you like) ---\n",
    "TABLE_NAME_SINGLE = \"your_single_table\"  # <<< REPLACE with an actual table name\n",
    "TABLE_NAMES_MULTIPLE = [\"your_table1\", \"your_table2\"] # <<< REPLACE\n",
    "CSV_DIR = \"downloaded_db_tables_csv\"\n",
    "\n",
    "# --- Example 1: List all tables ---\n",
    "# tables = list_tables()\n",
    "# if tables is not None: # Check if listing was successful (not None)\n",
    "#     print(f\"\\nAvailable tables: {tables if tables else 'None'}\")\n",
    "\n",
    "# --- Example 2: Download a SINGLE table to CSV ---\n",
    "# print(f\"\\nDownloading '{TABLE_NAME_SINGLE}' to CSV in '{CSV_DIR}'...\")\n",
    "# success = download_data(TABLE_NAME_SINGLE, output_dir=CSV_DIR, output_format='csv')\n",
    "# print(f\"Result: {'Success' if success else 'Failed'}\")\n",
    "\n",
    "# --- Example 3: Download a SINGLE table to Pandas DataFrame ---\n",
    "# print(f\"\\nDownloading '{TABLE_NAME_SINGLE}' to Pandas DataFrame...\")\n",
    "# df_one_table = download_data(TABLE_NAME_SINGLE, output_format='pandas')\n",
    "# if df_one_table is not None:\n",
    "#     print(f\"DataFrame for '{TABLE_NAME_SINGLE}' has {len(df_one_table)} rows.\")\n",
    "#     # display(df_one_table.head()) # In a notebook, 'display()' is often preferred for DataFrames\n",
    "# else:\n",
    "#     print(f\"Failed to get DataFrame for '{TABLE_NAME_SINGLE}'.\")\n",
    "\n",
    "# --- Example 4: Download MULTIPLE specified tables to CSV ---\n",
    "# print(f\"\\nDownloading {TABLE_NAMES_MULTIPLE} to CSV files in '{CSV_DIR}'...\")\n",
    "# success_multiple = download_data(TABLE_NAMES_MULTIPLE, output_dir=CSV_DIR, output_format='csv')\n",
    "# print(f\"Result: {'Overall/Partial Success' if success_multiple else 'Overall Failed'}. Check logs.\")\n",
    "\n",
    "# --- Example 5: Download MULTIPLE specified tables to Pandas DataFrames ---\n",
    "# print(f\"\\nDownloading {TABLE_NAMES_MULTIPLE} to Pandas DataFrames...\")\n",
    "# dict_of_dfs = download_data(TABLE_NAMES_MULTIPLE, output_format='pandas')\n",
    "# if dict_of_dfs: # Check if dictionary is not empty\n",
    "#     print(f\"Received {len(dict_of_dfs)} DataFrame(s):\")\n",
    "#     for name, df in dict_of_dfs.items():\n",
    "#         print(f\"  - '{name}': {len(df)} rows\")\n",
    "#         # display(df.head(2)) # Optionally display head of each\n",
    "# else:\n",
    "#     print(\"No DataFrames received or all failed.\")\n",
    "\n",
    "# --- Example 6: Download ALL tables to CSV ---\n",
    "print(f\"\\nDownloading ALL tables to CSV in '{CSV_DIR}/all_tables'...\")\n",
    "all_tables_csv_path = os.path.join(CSV_DIR, \"all_tables\")\n",
    "success_all = download_data('all', output_dir=all_tables_csv_path, output_format='csv')\n",
    "print(f\"Result: {'Overall/Partial Success' if success_all else 'Overall Failed'}. Check logs.\")\n",
    "\n",
    "# --- Example 7: Download ALL tables to Pandas DataFrames ---\n",
    "# print(f\"\\nDownloading ALL tables to Pandas DataFrames...\")\n",
    "# all_tables_dfs = download_data('all', output_format='pandas')\n",
    "# if all_tables_dfs:\n",
    "#     print(f\"Received {len(all_tables_dfs)} DataFrame(s) for all tables:\")\n",
    "#     for name, df in all_tables_dfs.items():\n",
    "#         print(f\"  - '{name}': {len(df)} rows\")\n",
    "# else:\n",
    "#     print(\"No DataFrames received or database is empty/all failed.\")\n",
    "\n",
    "# --- Example 8: Test non-existent table (Pandas) ---\n",
    "# print(f\"\\nDownloading non-existent table 'fantasy_table_123' to Pandas...\")\n",
    "# df_non_existent = download_data(\"fantasy_table_123\", output_format='pandas')\n",
    "# if df_non_existent is None:\n",
    "#     print(\"Correctly returned None for non-existent table.\")\n",
    "# else:\n",
    "#     print(\"Unexpected: Did not return None for non-existent table.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "def get_db_config():\n",
    "    \"\"\"Get database configuration from environment variables.\"\"\"\n",
    "    return {\n",
    "        'host': os.getenv('DB_HOST', 'localhost'),\n",
    "        'user': os.getenv('DB_USERNAME'),\n",
    "        'password': os.getenv('DB_PASS'),\n",
    "        'database': os.getenv('DB_NAME'),\n",
    "        'port': int(os.getenv('DB_PORT', '3306')),\n",
    "        'charset': os.getenv('DB_CHARSET', 'utf8mb4'),\n",
    "        'collation': os.getenv('DB_COLLATION', 'utf8mb4_general_ci')\n",
    "    }\n",
    "\n",
    "def create_connection():\n",
    "    \"\"\"Create a database connection from .env configuration.\"\"\"\n",
    "    connection = None\n",
    "    try:\n",
    "        db_config = get_db_config()\n",
    "        connection = mysql.connector.connect(**db_config)\n",
    "        if connection.is_connected():\n",
    "            print(f\"Successfully connected to MariaDB at {db_config['host']}\")\n",
    "            print(f\"Connected to server version {connection.get_server_info()}\")\n",
    "            print(f\"Database: {db_config['database']}\")\n",
    "            return connection\n",
    "    except Error as e:\n",
    "        print(f\"Error connecting to MariaDB: {e}\")\n",
    "        print(\"\\nConnection details (excluding password):\")\n",
    "        safe_config = {k: v for k, v in get_db_config().items() if k != 'password'}\n",
    "        print(safe_config)\n",
    "        return None\n",
    "\n",
    "def upload_csv_to_db(csv_file_path, table_name, if_exists='replace', chunk_size=None):\n",
    "    \"\"\"Upload a CSV file to a MariaDB table with improved handling for large tables.\n",
    "    \n",
    "    Args:\n",
    "        csv_file_path: Path to the CSV file\n",
    "        table_name: Name of the table to create or use\n",
    "        if_exists: What to do if the table already exists ('replace', 'append', 'fail')\n",
    "        chunk_size: Process CSV in chunks of this size (None to load entire file)\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if successful, False otherwise\n",
    "    \"\"\"\n",
    "    connection = create_connection()\n",
    "    if not connection:\n",
    "        print(\"Failed to connect to database\")\n",
    "        return False\n",
    "    \n",
    "    cursor = None\n",
    "    try:\n",
    "        # First, sample the data to understand its structure\n",
    "        # Read a sample to analyze column types\n",
    "        sample_size = 1000  # Adjust based on your data size\n",
    "        sample_df = pd.read_csv(csv_file_path, nrows=sample_size)\n",
    "        \n",
    "        print(f\"Detected {len(sample_df.columns)} columns in CSV file\")\n",
    "        \n",
    "        # Create a dictionary to store column types and a mapping for column names\n",
    "        column_types = {}\n",
    "        column_name_mapping = {}\n",
    "        \n",
    "        # Create mapping from original column names to clean column names\n",
    "        for column in sample_df.columns:\n",
    "            clean_column = ''.join(e for e in column if e.isalnum() or e == '_')\n",
    "            column_name_mapping[column] = clean_column\n",
    "        \n",
    "        # Rename columns in the sample dataframe\n",
    "        sample_df.rename(columns=column_name_mapping, inplace=True)\n",
    "        \n",
    "        # Preprocess the sample data to get a better understanding of column types\n",
    "        for column in sample_df.columns:\n",
    "            # Check if column contains any non-numeric values\n",
    "            if sample_df[column].dtype == 'object':\n",
    "                # If it's a string column, check if it could be numeric\n",
    "                try:\n",
    "                    # Try to convert to numeric\n",
    "                    pd.to_numeric(sample_df[column], errors='raise')\n",
    "                    # If successful, it's likely a numeric column\n",
    "                    column_types[column] = \"FLOAT\"\n",
    "                except:\n",
    "                    # If conversion fails, it contains non-numeric values\n",
    "                    column_types[column] = \"TEXT\"\n",
    "            elif pd.api.types.is_integer_dtype(sample_df[column].dtype):\n",
    "                column_types[column] = \"INT\"\n",
    "            elif pd.api.types.is_float_dtype(sample_df[column].dtype):\n",
    "                column_types[column] = \"FLOAT\"\n",
    "            elif pd.api.types.is_bool_dtype(sample_df[column].dtype):\n",
    "                column_types[column] = \"BOOLEAN\"\n",
    "            elif pd.api.types.is_datetime64_any_dtype(sample_df[column].dtype):\n",
    "                column_types[column] = \"DATETIME\"\n",
    "            else:\n",
    "                column_types[column] = \"TEXT\"\n",
    "        \n",
    "        # Now, process the entire file or in chunks\n",
    "        if chunk_size:\n",
    "            # Process in chunks\n",
    "            df_iterator = pd.read_csv(csv_file_path, chunksize=chunk_size)\n",
    "            first_chunk = next(df_iterator)\n",
    "            # Rename columns in first chunk\n",
    "            first_chunk.rename(columns=column_name_mapping, inplace=True)\n",
    "            df_chunks = [first_chunk]\n",
    "            \n",
    "            # Rename columns in remaining chunks\n",
    "            remaining_chunks = []\n",
    "            for chunk in df_iterator:\n",
    "                chunk.rename(columns=column_name_mapping, inplace=True)\n",
    "                remaining_chunks.append(chunk)\n",
    "            \n",
    "            df_chunks.extend(remaining_chunks)\n",
    "        else:\n",
    "            # Read the entire CSV file\n",
    "            df = pd.read_csv(csv_file_path)\n",
    "            print(f\"Read {len(df)} rows from {csv_file_path}\")\n",
    "            # Rename columns in the full dataframe\n",
    "            df.rename(columns=column_name_mapping, inplace=True)\n",
    "            df = df.replace({np.nan: None})\n",
    "        \n",
    "        cursor = connection.cursor()\n",
    "        \n",
    "        # Check if table exists\n",
    "        cursor.execute(f\"SHOW TABLES LIKE '{table_name}'\")\n",
    "        table_exists = cursor.fetchone() is not None\n",
    "        \n",
    "        if table_exists:\n",
    "            if if_exists == 'fail':\n",
    "                print(f\"Table '{table_name}' already exists. Aborting.\")\n",
    "                return False\n",
    "            elif if_exists == 'replace':\n",
    "                print(f\"Dropping existing table '{table_name}'\")\n",
    "                cursor.execute(f\"DROP TABLE {table_name}\")\n",
    "                connection.commit()\n",
    "                table_exists = False\n",
    "        \n",
    "        # Create table if it doesn't exist\n",
    "        if not table_exists:\n",
    "            # Use the column types we detected earlier\n",
    "            column_defs = []\n",
    "            \n",
    "            # Process each column to create the table definition\n",
    "            for column in sample_df.columns:\n",
    "                sql_type = column_types.get(column, \"TEXT\")  # Default to TEXT if not found\n",
    "                \n",
    "                # Special handling for MoveIn column which caused the error in the past\n",
    "                if column == 'MoveIn':\n",
    "                    sql_type = \"TEXT\"  # Force TEXT for MoveIn\n",
    "                \n",
    "                column_defs.append(f\"`{column}` {sql_type}\")\n",
    "            \n",
    "            # Create table\n",
    "            create_table_sql = f\"CREATE TABLE {table_name} ({', '.join(column_defs)})\"\n",
    "            print(f\"Creating table with SQL: {create_table_sql}\")\n",
    "            cursor.execute(create_table_sql)\n",
    "            connection.commit()\n",
    "            print(f\"Table '{table_name}' created successfully\")\n",
    "        \n",
    "        # Insert data\n",
    "        def insert_dataframe(df_to_insert):\n",
    "            # Prepare the SQL placeholders and column names\n",
    "            placeholders = ', '.join(['%s'] * len(df_to_insert.columns))\n",
    "            columns = ', '.join(f'`{col}`' for col in df_to_insert.columns)\n",
    "            \n",
    "            insert_sql = f\"INSERT INTO {table_name} ({columns}) VALUES ({placeholders})\"\n",
    "            \n",
    "            # Convert DataFrame to list of tuples\n",
    "            values = df_to_insert.replace({np.nan: None}).values.tolist()\n",
    "            \n",
    "            # Execute in batches to avoid memory issues with large datasets\n",
    "            batch_size = 1000\n",
    "            for i in range(0, len(values), batch_size):\n",
    "                batch = values[i:i+batch_size]\n",
    "                cursor.executemany(insert_sql, batch)\n",
    "                connection.commit()\n",
    "                print(f\"Inserted batch {i//batch_size + 1} ({len(batch)} rows)\")\n",
    "        \n",
    "        # Insert data from chunks or entire dataframe\n",
    "        if chunk_size:\n",
    "            total_rows = 0\n",
    "            for i, chunk in enumerate(df_chunks):\n",
    "                insert_dataframe(chunk)\n",
    "                total_rows += len(chunk)\n",
    "                print(f\"Processed chunk {i+1} with {len(chunk)} rows\")\n",
    "            print(f\"Successfully uploaded {total_rows} rows to table '{table_name}'\")\n",
    "        else:\n",
    "            insert_dataframe(df)\n",
    "            print(f\"Successfully uploaded {len(df)} rows to table '{table_name}'\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    except Error as e:\n",
    "        print(f\"Error uploading CSV to database: {e}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"General error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "    finally:\n",
    "        if cursor:\n",
    "            cursor.close()\n",
    "        if connection and connection.is_connected():\n",
    "            connection.close()\n",
    "            print(\"Database connection closed\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    csv_file = r\"d:\\OneDrive - Green Energy\\Desktop\\properties_202503181522.csv\"  # Replace with your CSV file path\n",
    "    table_name = \"property\"  # Replace with your desired table name\n",
    "    upload_csv_to_db(csv_file, table_name, chunk_size=50)  # Process in chunks of 50 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
